{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2d377946-678d-4997-9529-176264339bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d68957af-c1e2-41b4-a62e-bf2d18f211a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('titanic.train.csv')\n",
    "test = pd.read_csv('titanic.test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c4ba704b-65e3-4b20-8d94-78690b50a41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pclass', 'survived', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket',\n",
      "       'fare', 'cabin', 'embarked', 'boat', 'body', 'home.dest'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pclass                                 3\n",
       "survived                               1\n",
       "name         Sheerlinck, Mr. Jan Baptist\n",
       "sex                                 male\n",
       "age                                 29.0\n",
       "sibsp                                  0\n",
       "parch                                  0\n",
       "ticket                            345779\n",
       "fare                                 9.5\n",
       "cabin                                NaN\n",
       "embarked                               S\n",
       "boat                                  11\n",
       "body                                 NaN\n",
       "home.dest                            NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.columns)\n",
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "68c03e47-a60e-4535-a66e-f6d11f0b4ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697\n",
      "253\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "print(len(train['ticket'].unique()))\n",
    "print(len(train['fare'].unique()))\n",
    "print(len(train['cabin'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "958a6df6-ec2c-4601-abb5-bc141cc2e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_preprocess(train, test):\n",
    "    '''\n",
    "    Cleans and Preprocesses the inputted data to prepare it to be used for predictions in a model\n",
    "\n",
    "    Args:\n",
    "      data (pd.DataFrame): Dataframe containing titanic data\n",
    "    \n",
    "    Return:\n",
    "      X (pd.DataFrame): DataFrame containing cleaned input data for a model\n",
    "      y (pd.Series): Series containing target variables for a model\n",
    "    '''\n",
    "    columns = ['pclass', 'fare', 'sex', 'parch', 'sibsp', 'cabin']\n",
    "\n",
    "    \n",
    "    data = pd.concat([train, test])\n",
    "    # data = data.dropna(subset=columns)\n",
    "    \n",
    "    X = data[columns]\n",
    "    \n",
    "    one_hot_sex = pd.get_dummies(X['sex'])\n",
    "    X = X.drop('sex', axis=1)\n",
    "    X = pd.concat([X, one_hot_sex], axis=1)\n",
    "\n",
    "    one_hot_cabin = pd.get_dummies(X['cabin'])\n",
    "    X = X.drop('cabin', axis=1)\n",
    "    X = pd.concat([X, one_hot_cabin], axis=1)\n",
    "    \n",
    "    y = data['survived']\n",
    "\n",
    "    print(len(X))\n",
    "    print(len(y))\n",
    "    clean_X = X[~X.isna().any(axis=1)]\n",
    "    y = y[~X.isna().any(axis=1)]\n",
    "\n",
    "    print(len(clean_X))\n",
    "    print(len(y))\n",
    "    \n",
    "    X = clean_X.to_numpy().astype('float64')\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    return X[:len(train)], y[:len(train)], X[len(train):], y[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c27121f5-8b74-4541-be35-88aa2cd5b4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309\n",
      "1309\n",
      "1308\n",
      "1308\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = clean_preprocess(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2a07442a-c3b2-4902-a14c-92d16b40dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "\n",
    "    def __init__(self, lr=.0001):\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X, y, iterations=100):\n",
    "        costs = []\n",
    "\n",
    "        self.weights = np.random.randn(len(X[0]))\n",
    "        self.bias = np.random.randn()\n",
    "        \n",
    "        for _ in range(iterations):\n",
    "            scores = self.score(X)\n",
    "\n",
    "            self.weights -= self.lr * self.gradW(X, y, scores)\n",
    "            self.bias -= self.lr * self.gradB(y, scores)\n",
    "\n",
    "            costs.append(self.cost(y, scores))\n",
    "\n",
    "        return costs\n",
    "\n",
    "    def predict(self, X):\n",
    "        scores = self.score(X)\n",
    "\n",
    "        return [1 if score >= .5 else 0 for score in scores]\n",
    "\n",
    "    def evaluate(self, predictions, y):\n",
    "        tp, tn, fp, fn = (0, 0, 0, 0)\n",
    "        \n",
    "        for prediction, actual in zip(predictions, y):\n",
    "            if actual == prediction:\n",
    "                if prediction == 1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if prediction == 1:\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "\n",
    "        acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        fscore = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "        return acc, precision, recall, fscore\n",
    " \n",
    "    def score(self, X):\n",
    "        return self.sigmoid((self.weights @ X.T).T + self.bias)\n",
    "\n",
    "    def cost(self, y, scores):\n",
    "        cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
    "        \n",
    "        return -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores + 1e-9))\n",
    "\n",
    "    def gradW(self, X, y, scores):\n",
    "        return (np.expand_dims(scores - y, 0) @ X).sum(axis=0)\n",
    "\n",
    "    def gradB(self, y, scores):\n",
    "        return (scores - y).sum(axis=0)\n",
    "\n",
    "    def gradSigmoid(self, X):\n",
    "        return self.sigmoid(X) * (1 - self.sigmoid(X))\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3ca30dea-09b8-418b-9dcb-eb2a6216a3bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n",
      "/tmp/ipykernel_218308/2359982507.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -np.sum(y * np.log(scores) + (1 - y) * np.log(1 - scores))\n"
     ]
    }
   ],
   "source": [
    "log_regression = LogisticRegression(lr=.001)\n",
    "\n",
    "costs = log_regression.fit(train_X, train_y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6556f5b2-90c6-4b77-af9e-5e203c66c8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training Loss')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(costs)), costs)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8e59c061-276a-4b51-93b1-77b7ceece25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8282828282828283\n",
      "Test Accuracy: 0.7553956834532374\n"
     ]
    }
   ],
   "source": [
    "train_results = log_regression.evaluate(log_regression.predict(train_X), train_y)\n",
    "test_results = log_regression.evaluate(log_regression.predict(test_X), test_y)\n",
    "\n",
    "print(f'Train Accuracy: {train_results[0]:.4f}')\n",
    "print(f'Test Accuracy: {test_results[0]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ad99fa-f55e-435a-bfe1-af8002d15401",
   "metadata": {},
   "source": [
    "## Features Used\n",
    "The features I used to train my logistic regression model were 'pclass', 'fare', 'sex', 'parch', 'sibsp', 'cabin'. The 'cabin' and 'sex' variables are categorical, so I used one-hot encoding to capture the variables numerically.\n",
    "\n",
    "## Preprocessing\n",
    "To transform the data I one-hot encoded the categorical data. I then applied the Standard Scaler to all of the data so that all of our features are normalized and the scaling of the features does not impact the scale of our weights. \n",
    "\n",
    "## Learning Rate\n",
    "I used a learning rate of .001 as I found it operated the best in my testing by striking a balance between changing the weights every iteration and not ping-pong on either side of the local minima.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0ad6eed7-32f5-4f4a-917c-67e74aa470b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 8)                 1544      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1585 (6.19 KB)\n",
      "Trainable params: 1585 (6.19 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=len(train_X[0])),\n",
    "        layers.Dense(8, activation=\"relu\"),\n",
    "        layers.Dense(4, activation='relu'),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9567acf4-d09e-41aa-bed7-537b8a8f68b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8527 - accuracy: 0.3920 - val_loss: 0.8919 - val_accuracy: 0.3778\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8228 - accuracy: 0.4245 - val_loss: 0.8805 - val_accuracy: 0.5556\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8009 - accuracy: 0.6779 - val_loss: 0.8735 - val_accuracy: 0.6111\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7821 - accuracy: 0.7179 - val_loss: 0.8668 - val_accuracy: 0.6333\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7658 - accuracy: 0.7241 - val_loss: 0.8598 - val_accuracy: 0.6778\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7510 - accuracy: 0.7303 - val_loss: 0.8525 - val_accuracy: 0.6778\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7362 - accuracy: 0.7316 - val_loss: 0.8449 - val_accuracy: 0.6889\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7224 - accuracy: 0.7328 - val_loss: 0.8382 - val_accuracy: 0.6889\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7095 - accuracy: 0.7441 - val_loss: 0.8323 - val_accuracy: 0.7000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6973 - accuracy: 0.7466 - val_loss: 0.8255 - val_accuracy: 0.7111\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6851 - accuracy: 0.7503 - val_loss: 0.8180 - val_accuracy: 0.7222\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6725 - accuracy: 0.7528 - val_loss: 0.8104 - val_accuracy: 0.7111\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6603 - accuracy: 0.7516 - val_loss: 0.8026 - val_accuracy: 0.7111\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6478 - accuracy: 0.7541 - val_loss: 0.7950 - val_accuracy: 0.7111\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6360 - accuracy: 0.7578 - val_loss: 0.7874 - val_accuracy: 0.7111\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6251 - accuracy: 0.7591 - val_loss: 0.7798 - val_accuracy: 0.7111\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6140 - accuracy: 0.7615 - val_loss: 0.7726 - val_accuracy: 0.7111\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6030 - accuracy: 0.7615 - val_loss: 0.7659 - val_accuracy: 0.7111\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5927 - accuracy: 0.7640 - val_loss: 0.7597 - val_accuracy: 0.7000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5828 - accuracy: 0.7678 - val_loss: 0.7542 - val_accuracy: 0.7000\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5745 - accuracy: 0.7678 - val_loss: 0.7497 - val_accuracy: 0.7000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5659 - accuracy: 0.7690 - val_loss: 0.7461 - val_accuracy: 0.7000\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5581 - accuracy: 0.7690 - val_loss: 0.7429 - val_accuracy: 0.7000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5503 - accuracy: 0.7690 - val_loss: 0.7396 - val_accuracy: 0.7000\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5435 - accuracy: 0.7703 - val_loss: 0.7358 - val_accuracy: 0.7111\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5367 - accuracy: 0.7728 - val_loss: 0.7322 - val_accuracy: 0.7111\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7753 - val_loss: 0.7294 - val_accuracy: 0.7111\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5231 - accuracy: 0.7765 - val_loss: 0.7270 - val_accuracy: 0.7111\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5169 - accuracy: 0.7778 - val_loss: 0.7244 - val_accuracy: 0.7111\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5113 - accuracy: 0.7790 - val_loss: 0.7214 - val_accuracy: 0.7111\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5051 - accuracy: 0.7828 - val_loss: 0.7182 - val_accuracy: 0.7222\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.7840 - val_loss: 0.7155 - val_accuracy: 0.7222\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4949 - accuracy: 0.7840 - val_loss: 0.7131 - val_accuracy: 0.7222\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4903 - accuracy: 0.7853 - val_loss: 0.7111 - val_accuracy: 0.7222\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4858 - accuracy: 0.7890 - val_loss: 0.7091 - val_accuracy: 0.7222\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4816 - accuracy: 0.7890 - val_loss: 0.7073 - val_accuracy: 0.7222\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4774 - accuracy: 0.7903 - val_loss: 0.7055 - val_accuracy: 0.7222\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.7928 - val_loss: 0.7036 - val_accuracy: 0.7222\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7915 - val_loss: 0.7019 - val_accuracy: 0.7222\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7903 - val_loss: 0.7005 - val_accuracy: 0.7222\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4634 - accuracy: 0.7903 - val_loss: 0.6995 - val_accuracy: 0.7222\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7940 - val_loss: 0.6990 - val_accuracy: 0.7222\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4576 - accuracy: 0.7965 - val_loss: 0.6988 - val_accuracy: 0.7222\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4547 - accuracy: 0.8015 - val_loss: 0.6986 - val_accuracy: 0.7222\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4519 - accuracy: 0.8052 - val_loss: 0.6985 - val_accuracy: 0.7222\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4494 - accuracy: 0.8065 - val_loss: 0.6978 - val_accuracy: 0.7222\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4473 - accuracy: 0.8065 - val_loss: 0.6972 - val_accuracy: 0.7222\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4450 - accuracy: 0.8065 - val_loss: 0.6968 - val_accuracy: 0.7222\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4431 - accuracy: 0.8065 - val_loss: 0.6968 - val_accuracy: 0.7222\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.8090 - val_loss: 0.6970 - val_accuracy: 0.7222\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4397 - accuracy: 0.8102 - val_loss: 0.6971 - val_accuracy: 0.7222\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.8102 - val_loss: 0.6972 - val_accuracy: 0.7222\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.8115 - val_loss: 0.6974 - val_accuracy: 0.7222\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.8090 - val_loss: 0.6977 - val_accuracy: 0.7222\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4339 - accuracy: 0.8115 - val_loss: 0.6974 - val_accuracy: 0.7222\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4325 - accuracy: 0.8127 - val_loss: 0.6969 - val_accuracy: 0.7222\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4312 - accuracy: 0.8127 - val_loss: 0.6970 - val_accuracy: 0.7222\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.8140 - val_loss: 0.6973 - val_accuracy: 0.7222\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.8140 - val_loss: 0.6974 - val_accuracy: 0.7222\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.8140 - val_loss: 0.6973 - val_accuracy: 0.7222\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.8140 - val_loss: 0.6972 - val_accuracy: 0.7222\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8140 - val_loss: 0.6975 - val_accuracy: 0.7222\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.8140 - val_loss: 0.6975 - val_accuracy: 0.7222\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8152 - val_loss: 0.6979 - val_accuracy: 0.7222\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.8177 - val_loss: 0.6985 - val_accuracy: 0.7222\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8177 - val_loss: 0.6991 - val_accuracy: 0.7222\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8177 - val_loss: 0.6996 - val_accuracy: 0.7222\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8190 - val_loss: 0.7003 - val_accuracy: 0.7222\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.8202 - val_loss: 0.7012 - val_accuracy: 0.7222\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8190 - val_loss: 0.7023 - val_accuracy: 0.7222\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8177 - val_loss: 0.7031 - val_accuracy: 0.7222\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8177 - val_loss: 0.7038 - val_accuracy: 0.7222\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4149 - accuracy: 0.8177 - val_loss: 0.7044 - val_accuracy: 0.7222\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8177 - val_loss: 0.7045 - val_accuracy: 0.7222\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8177 - val_loss: 0.7044 - val_accuracy: 0.7222\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8177 - val_loss: 0.7046 - val_accuracy: 0.7222\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8215 - val_loss: 0.7049 - val_accuracy: 0.7222\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8215 - val_loss: 0.7053 - val_accuracy: 0.7222\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8215 - val_loss: 0.7057 - val_accuracy: 0.7222\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8215 - val_loss: 0.7060 - val_accuracy: 0.7222\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4097 - accuracy: 0.8215 - val_loss: 0.7058 - val_accuracy: 0.7222\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.8215 - val_loss: 0.7056 - val_accuracy: 0.7222\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4083 - accuracy: 0.8215 - val_loss: 0.7055 - val_accuracy: 0.7222\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8215 - val_loss: 0.7053 - val_accuracy: 0.7222\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4069 - accuracy: 0.8215 - val_loss: 0.7054 - val_accuracy: 0.7222\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8215 - val_loss: 0.7054 - val_accuracy: 0.7222\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4056 - accuracy: 0.8215 - val_loss: 0.7056 - val_accuracy: 0.7222\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8227 - val_loss: 0.7055 - val_accuracy: 0.7333\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8227 - val_loss: 0.7046 - val_accuracy: 0.7444\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4033 - accuracy: 0.8277 - val_loss: 0.7044 - val_accuracy: 0.7444\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8327 - val_loss: 0.7042 - val_accuracy: 0.7444\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4015 - accuracy: 0.8340 - val_loss: 0.7043 - val_accuracy: 0.7444\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4007 - accuracy: 0.8340 - val_loss: 0.7045 - val_accuracy: 0.7444\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8327 - val_loss: 0.7048 - val_accuracy: 0.7444\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8340 - val_loss: 0.7050 - val_accuracy: 0.7444\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8340 - val_loss: 0.7051 - val_accuracy: 0.7444\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8327 - val_loss: 0.7053 - val_accuracy: 0.7444\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3974 - accuracy: 0.8327 - val_loss: 0.7056 - val_accuracy: 0.7444\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8315 - val_loss: 0.7062 - val_accuracy: 0.7444\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8327 - val_loss: 0.7068 - val_accuracy: 0.7444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7ba017f3d0>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_X, train_y, batch_size=256, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "01c94657-d0c3-4a5b-9da2-cf8fe2bb5f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 844us/step - loss: 0.7500 - accuracy: 0.7482\n",
      "Accuracy of NN model: 0.7482\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_X, test_y)\n",
    "print(f'Accuracy of NN model: {scores[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8ac220-f115-4204-9807-71826e7d4335",
   "metadata": {},
   "source": [
    "# Model Architecure Graph\n",
    "!['Model Architechure Graph'](model_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b475e-765c-41e9-bd3f-d3bf8729b51e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
